{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1R_tHayHF0s",
        "outputId": "e0b49c4e-c65c-4345-c93b-f44638a8f5a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Usage:   \n",
            "  pip3 <command> [options]\n",
            "\n",
            "no such option: -p\n",
            "Cloning into 'wide-resnet.pytorch'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 124 (delta 29), reused 29 (delta 29), pack-reused 89\u001b[K\n",
            "Receiving objects: 100% (124/124), 670.63 KiB | 5.28 MiB/s, done.\n",
            "Resolving deltas: 100% (66/66), done.\n"
          ]
        }
      ],
      "source": [
        "!pip -p install http://download.pytorch.org/whl/cu80/torch-0.1.12.post2-cp27-none-linux_x86_64.whl\n",
        "!git clone https://github.com/meliketoy/wide-resnet.pytorch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDVh_mFsHu9X"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rand\n",
        "import torch\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "import pandas as pd\n",
        "\n",
        "import pickle\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9wyaNwiHee9",
        "outputId": "fb77ab02-ef5d-4112-ace5-14c4df1f3692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:02<00:00, 66698378.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n"
          ]
        }
      ],
      "source": [
        "train_data=CIFAR10(root=\"data\",train=True,download=True,transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUUAkmeBHiF3",
        "outputId": "93210629-a453-4886-fc73-f189cfc7d622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "test_data = CIFAR10(root=\"data\",train=False,download=True,transform=ToTensor())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw77wcpjN6or",
        "outputId": "8c1a41f3-2f93-43bd-8664-5fda07110825"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['readme.html', 'batches.meta', 'data_batch_2', 'data_batch_5', 'test_batch', 'data_batch_3', 'data_batch_4', 'data_batch_1']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "print(os.listdir(\"./data/cifar-10-batches-py\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OvPw9n5gOLn1",
        "outputId": "f394313b-4891-42ed-b6d8-8da3abf57e38"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUvIuyBHONnY"
      },
      "outputs": [],
      "source": [
        "def load_cifar10_data(filename):\n",
        "    with open('./data/cifar-10-batches-py/'+ filename, 'rb') as file:\n",
        "        batch = pickle.load(file, encoding='latin1')\n",
        "\n",
        "    features = batch['data']\n",
        "    labels = batch['labels']\n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wVq19jJPwY7"
      },
      "outputs": [],
      "source": [
        "batch_1, labels_1 = load_cifar10_data('data_batch_1')\n",
        "batch_2, labels_2 = load_cifar10_data('data_batch_2')\n",
        "batch_3, labels_3 = load_cifar10_data('data_batch_3')\n",
        "batch_4, labels_4 = load_cifar10_data('data_batch_4')\n",
        "batch_5, labels_5 = load_cifar10_data('data_batch_5')\n",
        "\n",
        "test, label_test = load_cifar10_data('test_batch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8q3raJMP4fC"
      },
      "outputs": [],
      "source": [
        "X_train = np.concatenate([batch_1,batch_2,batch_3,batch_4,batch_5], 0)\n",
        "X_test=np.concatenate([test])\n",
        "Y_train = np.concatenate([labels_1,labels_2,labels_3,labels_4,labels_5], 0)\n",
        "Y_test=np.concatenate([label_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jk4fMA0P8CL",
        "outputId": "e4ad2080-ae30-46f0-cc33-eb8a937a50d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (50000, 3072)\n",
            "Y_train shape: (50000,)\n",
            "X_test shape: (10000, 3072)\n",
            "Y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "print('X_train shape:', X_train.shape)\n",
        "print('Y_train shape:', Y_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('Y_test shape:', Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRnm4U4GQZNQ"
      },
      "outputs": [],
      "source": [
        "classes = ('airplane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "def return_photo(batch_file):\n",
        "    assert batch_file.shape[1] == 3072\n",
        "    dim = np.sqrt(1024).astype(int)\n",
        "    r = batch_file[:, 0:1024].reshape(batch_file.shape[0], dim, dim, 1)\n",
        "    g = batch_file[:, 1024:2048].reshape(batch_file.shape[0], dim, dim, 1)\n",
        "    b = batch_file[:, 2048:3072].reshape(batch_file.shape[0], dim, dim, 1)\n",
        "    photo = np.concatenate([r,g,b], -1)\n",
        "    return photo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDBBjLcLRVtI"
      },
      "outputs": [],
      "source": [
        "X_train = return_photo(X_train)\n",
        "X_test = return_photo(test)\n",
        "Y_test = np.array(label_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsKs_WyIShmQ",
        "outputId": "a974de2c-047d-4bf9-fc18-10ff1c17c4ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (50000, 32, 32, 3)\n",
            "Y_train shape: (50000,)\n",
            "X_test shape: (10000, 32, 32, 3)\n",
            "Y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "print('X_train shape:', X_train.shape)\n",
        "print('Y_train shape:', Y_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('Y_test shape:', Y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "OsY53YE-QZpA",
        "outputId": "6ccab525-06b6-4a2a-9ce6-e141d5e6e397"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 300x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 300x200 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def plot_image(number, file, label, pred=None):\n",
        "    fig = plt.figure(figsize = (3,2))\n",
        "    #img = return_photo(batch_file)\n",
        "    plt.imshow(file[number])\n",
        "    if pred is None:\n",
        "        plt.title(classes[label[number]])\n",
        "    else:\n",
        "        plt.title('Label_true: ' + classes[label[number]] + '\\nLabel_pred: ' + classes[pred[number]])\n",
        "\n",
        "plot_image(12345, X_train, Y_train)\n",
        "plot_image(1, X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tho4IcH9GDf7"
      },
      "outputs": [],
      "source": [
        "mean=[0.485, 0.456, 0.406]\n",
        "std=[0.229, 0.224, 0.225]\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "def normalize_dataset(data):\n",
        "    mean = data.mean(axis=(0,1,2)) / 255.0\n",
        "    std = data.std(axis=(0,1,2)) / 255.0\n",
        "    normalize = transforms.Normalize(mean=mean, std=std)\n",
        "    return normalize\n",
        "\n",
        "def get_transform():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandAugment(),\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    return transform\n",
        "\n",
        "def simple_transform():\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((32, 32)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    return transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhPQqWQjIwHY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# define the random seed for reproducible result\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "\n",
        "class CIFAR10_from_array(Dataset):\n",
        "    def __init__(self, data, label, transform=None):\n",
        "\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "        self.transform = transform\n",
        "        self.img_shape = data.shape\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        img = Image.fromarray(self.data[index])\n",
        "        label = self.label[index]\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        else:\n",
        "            img_to_tensor = transforms.ToTensor()\n",
        "            img = img_to_tensor(img)\n",
        "            #label = torch.from_numpy(label).long()\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def plot_image(self, number):\n",
        "        file = self.data\n",
        "        label = self.label\n",
        "        fig = plt.figure(figsize = (3,2))\n",
        "        #img = return_photo(batch_file)\n",
        "        plt.imshow(file[number])\n",
        "        plt.title(classes[label[number]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyPj5VEQJbWs"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_unlabelled, X_labelled, y_unlabelled, y_labelled = train_test_split(X_train, Y_train, test_size=0.2, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fa7NOTsBR-Dm"
      },
      "outputs": [],
      "source": [
        "def normalize_dataset(data):\n",
        "    mean = data.mean(axis=(0,1,2)) / 255.0\n",
        "    std = data.std(axis=(0,1,2)) / 255.0\n",
        "    normalize = transforms.Normalize(mean=mean, std=std)\n",
        "    return normalize\n",
        "\n",
        "train_transform_aug = transforms.Compose([\n",
        "    transforms.Resize((40, 40)),\n",
        "    transforms.RandomCrop((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    normalize_dataset(X_unlabelled)\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_dataset(X_labelled)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize_dataset(X_test)\n",
        "])\n",
        "\n",
        "unlabelled_trainset = CIFAR10_from_array(data=X_unlabelled, label=y_unlabelled, transform=train_transform_aug)\n",
        "unlabelled_trainset_aug = CIFAR10_from_array(data=X_unlabelled, label=y_unlabelled, transform=val_transform)\n",
        "labelled_trainset = CIFAR10_from_array(data=X_labelled, label=y_labelled, transform=val_transform)\n",
        "testset = CIFAR10_from_array(data=X_test, label=Y_test, transform=test_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OpmEnqgiSljf",
        "outputId": "182c3a27-52d7-4d70-9945-1b8dfb3f1d05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training set:       (40000, 32, 32, 3)\n",
            "validation set:     (10000, 32, 32, 3)\n",
            "testing set:        (10000, 32, 32, 3)\n",
            "label numbers:      10\n"
          ]
        }
      ],
      "source": [
        "print('training set:'.ljust(20) + '{}'.format(unlabelled_trainset.img_shape))\n",
        "print('validation set:'.ljust(20) + '{}'.format(labelled_trainset.img_shape))\n",
        "print('testing set:'.ljust(20) + '{}'.format(testset.img_shape))\n",
        "print('label numbers:'.ljust(20) + '{}'.format(len(set(labelled_trainset.label))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9RDlKPIOSzL6"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = 1\n",
        "\n",
        "unlabelled_train_loader = DataLoader(dataset=unlabelled_trainset,batch_size=batch_size, shuffle=True,num_workers=num_workers)\n",
        "unlabelled_train_loader_aug = DataLoader(dataset=unlabelled_trainset_aug,batch_size=batch_size, shuffle=True,num_workers=num_workers)\n",
        "labelled_train_loader = DataLoader(dataset=labelled_trainset,batch_size=batch_size, shuffle=False,num_workers=num_workers)\n",
        "test_loader = DataLoader(dataset=testset,batch_size=batch_size, shuffle=False,num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "T1MKfPFKTZs3"
      },
      "outputs": [],
      "source": [
        "unlabelled_iterable = iter(unlabelled_train_loader)\n",
        "unlabelled_iterable_aug = iter(unlabelled_train_loader_aug)\n",
        "labelled_iterable = iter(labelled_train_loader)\n",
        "test_iterable = iter(test_loader)\n",
        "# imgs, lbls = next(unlabelled_iterable)\n",
        "# print ('Size of image:', imgs.size())\n",
        "# print ('Type of image:', imgs.dtype)\n",
        "# print ('Size of label:', lbls.size())\n",
        "# print ('Type of label:', lbls.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UJWn0fPsUqNp",
        "outputId": "deddbe1f-01d9-4b6d-8d2b-8e8c6291b8f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Wide-Resnet 28x10\n",
            "torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "def conv_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        init.xavier_uniform_(m.weight, gain=np.sqrt(2))\n",
        "        init.constant_(m.bias, 0)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        init.constant_(m.weight, 1)\n",
        "        init.constant_(m.bias, 0)\n",
        "\n",
        "class wide_basic(nn.Module):\n",
        "    def __init__(self, in_planes, planes, dropout_rate, stride=1):\n",
        "        super(wide_basic, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, padding=1, bias=True)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=True)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=True),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.dropout(self.conv1(F.relu(self.bn1(x))))\n",
        "        out = self.conv2(F.relu(self.bn2(out)))\n",
        "        out += self.shortcut(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Wide_ResNet(nn.Module):\n",
        "    def __init__(self, depth, widen_factor, dropout_rate, num_classes):\n",
        "        super(Wide_ResNet, self).__init__()\n",
        "        self.in_planes = 16\n",
        "\n",
        "        assert ((depth-4)%6 ==0), 'Wide-resnet depth should be 6n+4'\n",
        "        n = (depth-4)/6\n",
        "        k = widen_factor\n",
        "\n",
        "        print('| Wide-Resnet %dx%d' %(depth, k))\n",
        "        nStages = [16, 16*k, 32*k, 64*k]\n",
        "\n",
        "        self.conv1 = conv3x3(3,nStages[0])\n",
        "        self.layer1 = self._wide_layer(wide_basic, nStages[1], n, dropout_rate, stride=1)\n",
        "        self.layer2 = self._wide_layer(wide_basic, nStages[2], n, dropout_rate, stride=2)\n",
        "        self.layer3 = self._wide_layer(wide_basic, nStages[3], n, dropout_rate, stride=2)\n",
        "        self.bn1 = nn.BatchNorm2d(nStages[3], momentum=0.9)\n",
        "        self.linear = nn.Linear(nStages[3], num_classes)\n",
        "\n",
        "    def _wide_layer(self, block, planes, num_blocks, dropout_rate, stride):\n",
        "        strides = [stride] + [1]*(int(num_blocks)-1)\n",
        "        layers = []\n",
        "\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, dropout_rate, stride))\n",
        "            self.in_planes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    net=Wide_ResNet(28, 10, 0.3, 10)\n",
        "    y = net(Variable(torch.randn(1,3,32,32)))\n",
        "\n",
        "    print(y.size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_N627gEyU3ny",
        "outputId": "7da75c1a-0cce-471f-a15e-d101f9dedc3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Wide-Resnet 28x2\n"
          ]
        }
      ],
      "source": [
        "model = Wide_ResNet(28,2,0.3,10).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RkOFWGO4WZd8"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "    correct = torch.eq(y_true.to(device), y_pred.to(device)).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "beta_0 = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dz7P1i2DlAO2"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "acc=0\n",
        "\n",
        "EPOCHS = 100\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  for epoch in range(len(unlabelled_train_loader)):\n",
        "    labeled_images, labels = next(labelled_iterable)\n",
        "    unlabeled_images,donttake = next(unlabelled_iterable)\n",
        "    unlabeled_images_aug,donttake_aug = next(unlabelled_iterable_aug)\n",
        "\n",
        "    pseudo_labels = torch.argmax(torch.softmax(model(unlabeled_images.to(device)), dim=1), dim=1).to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    unlabeled_logits_aug = model(unlabeled_images_aug.to(device)).to(device)\n",
        "    unlabeled_logits = model(unlabeled_images.to(device)).to(device)\n",
        "    labeled_logits = model(labeled_images.to(device)).to(device)\n",
        "\n",
        "    loss_1 = nn.CrossEntropyLoss()(unlabeled_logits_aug, pseudo_labels)\n",
        "    loss_labelled_1 = nn.CrossEntropyLoss()(labeled_logits.to(device), labels.to(device)).to(device)\n",
        "\n",
        "    (loss_1).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    new_labeled_logits = model(labeled_images.to(device)).to(device)\n",
        "    loss_labelled_2 = nn.CrossEntropyLoss()(new_labeled_logits, labels.to(device)).to(device)\n",
        "\n",
        "    new_unlabeled_logits = model(unlabeled_images.to(device)).to(device)\n",
        "    new_unlabeled_logits_aug = model(unlabeled_images_aug.to(device)).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        pseudo_labels_unlabeled = torch.softmax(model(unlabeled_images.to(device)).to(device), dim=1)\n",
        "\n",
        "    beta_k = beta_0 * torch.min(torch.tensor(1,dtype=torch.float32), ((epoch + torch.tensor(1,dtype=torch.float32)) /torch.tensor(8,dtype=torch.float32)))\n",
        "\n",
        "    mask, dontcare = torch.max(torch.softmax(new_unlabeled_logits_aug, dim=1), dim=1)\n",
        "\n",
        "    loss_partial = beta_k * torch.mean(torch.sum(-(torch.softmax(new_unlabeled_logits, dim=1)) * torch.log(torch.softmax(new_unlabeled_logits_aug, dim=1)), dim=-1) * mask)\n",
        "\n",
        "    loss_uda = loss_labelled_2 + loss_partial\n",
        "\n",
        "    with torch.no_grad():\n",
        "        new_pseudo_labels = torch.argmax(torch.softmax(new_unlabeled_logits, dim=1), dim=1).to(device)\n",
        "\n",
        "    new_loss = loss_labelled_2.item()\n",
        "    old_loss = loss_labelled_1.item()\n",
        "    change = new_loss - old_loss\n",
        "    loss_mpl = ((change) * (nn.CrossEntropyLoss()(new_unlabeled_logits, new_pseudo_labels)))\n",
        "\n",
        "    loss_2 = loss_uda + loss_mpl\n",
        "    (loss_2).backward()\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for batch in range(len(test_loader)):\n",
        "      test_images, test_labels = next(test_iterable)\n",
        "\n",
        "      test_logits = model(test_images.to(device))\n",
        "      pred_labels = torch.argmax(torch.softmax(test_logits, dim=1).to(device), dim=1).to(device)\n",
        "      acc += accuracy_fn(test_labels, pred_labels)\n",
        "\n",
        "  print(\"Accuracy per epoch :\", acc / len(test_loader))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qy_YvOfRpch_"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, criterion, device):\n",
        "  acc=0\n",
        "  torch.manual_seed(43)\n",
        "  test_batches = iter(test_loader)\n",
        "  torch.manual_seed(43)\n",
        "  labeled_batches = iter(labelled_trainset)\n",
        "  model.eval()\n",
        "  for _ in range(len(test_loader)):\n",
        "    try:\n",
        "        test_images, test_labels = next(test_batches)\n",
        "    except StopIteration:\n",
        "        test_batches = iter(test_loader)\n",
        "        test_images, test_labels = next(test_batches)\n",
        "\n",
        "    test_logits = model(test_images.to(device))\n",
        "    pred_labels = torch.argmax(torch.softmax(test_logits,dim=1).to(device),dim=1).to(device)\n",
        "    acc += accuracy_fn(test_labels, pred_labels)\n",
        "\n",
        "  print(\"Accuracy per epoch :\", acc/len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gePdBN3wlg9U"
      },
      "outputs": [],
      "source": [
        "evaluate_model(model, test_loader, criterion, device)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}